%% abtex2-modelo-trabalho-academico.tex, v-1.9 laurocesar
%% Copyright 2012-2013 by abnTeX2 group at http://abntex2.googlecode.com/ 
%%
%% This work may be distributed and/or modified under the
%% conditions of the LaTeX Project Public License, either version 1.3
%% of this license or (at your option) any later version.
%% The latest version of this license is in
%%   http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 2005/12/01 or later.
%%
%% This work has the LPPL maintenance status `maintained'.
%% 
%% The Current Maintainer of this work is the abnTeX2 team, led
%% by Lauro César Araujo. Further information are available on 
%% http://abntex2.googlecode.com/
%%
%% This work consists of the files abntex2-modelo-trabalho-academico.tex,
%% abntex2-modelo-include-comandos and abntex2-modelo-references.bib
%%

% ------------------------------------------------------------------------
% ------------------------------------------------------------------------
% abnTeX2: Modelo de Trabalho Academico (tese de doutorado, dissertacao de
% mestrado e trabalhos monograficos em geral) em conformidade com 
% ABNT NBR 14724:2011: Informacao e documentacao - Trabalhos academicos -
% Apresentacao
% ------------------------------------------------------------------------
% ------------------------------------------------------------------------

\documentclass[
	% -- opções da classe memoir --
	12pt,				% tamanho da fonte
	openright,			% capítulos começam em pág ímpar (insere página vazia caso preciso)
	oneside,			% para impressão em verso e anverso. Oposto a oneside
	a4paper,			% tamanho do papel. 
	% -- opções da classe abntex2 --
	chapter=TITLE,		% títulos de capítulos convertidos em letras maiúsculas
	section=TITLE,		% títulos de seções convertidos em letras maiúsculas
	%subsection=TITLE,	% títulos de subseções convertidos em letras maiúsculas
	%subsubsection=TITLE,% títulos de subsubseções convertidos em letras maiúsculas
	% -- opções do pacote babel --
	english,			% idioma adicional para hifenização
	french,				% idioma adicional para hifenização
	spanish,			% idioma adicional para hifenização
	brazil				% o último idioma é o principal do documento
	]{abntex2}

% ---
% PACOTES
% ---

% ---
% Pacotes fundamentais 
% ---
%\usepackage{lmodern}			% Usa a fonte Latin Modern			
\usepackage{times}			% Usa a fonte Times
\usepackage[T1]{fontenc}		% Selecao de codigos de fonte.
\usepackage[utf8]{inputenc}		% Codificacao do documento (conversão automática dos acentos)
\usepackage{lastpage}			% Usado pela Ficha catalográfica
\usepackage{indentfirst}		% Indenta o primeiro parágrafo de cada seção.
\usepackage{color}			% Controle das cores
\usepackage{graphicx}			% Inclusão de gráficos
\usepackage{microtype} 			% para melhorias de justificação
\usepackage{listings}			% para inserir código fonte

% ---
% Pacotes de citações
% ---
\usepackage[brazilian,hyperpageref]{backref}	 % Paginas com as citações na bibl
\usepackage[alf]{abntex2cite}	% Citações padrão ABNT
\usepackage{titlesec}

% --- 
% CONFIGURAÇÕES DE PACOTES
% --- 

% altera o espacamento depois do número de cada secao, subsecao, etc
\titleformat{\section}
  {\normalfont\normalsize}{}{0pt}{\thesection\space}
\titleformat{\subsection}
  {\normalfont\normalsize\bfseries}{}{0pt}{\thesubsection\space}
\titleformat{\subsubsection}
  {\normalfont\normalsize}{}{0pt}{\thesubsubsection\space}
\titleformat{\paragraph}
  {\normalfont\normalsize\itshape}{}{0pt}{\theparagraph\space}

% ---
% Configurações do pacote backref
% Usado sem a opção hyperpageref de backref
\renewcommand{\backrefpagesname}{Citado na(s) página(s):~}
% Texto padrão antes do número das páginas
\renewcommand{\backref}{}
% Define os textos da citação
\renewcommand*{\backrefalt}[4]{
	\ifcase #1 %
		Nenhuma citação no texto.%
	\or
		Citado na página #2.%
	\else
		Citado #1 vezes nas páginas #2.%
	\fi}%
% ---

% ---
% **************************************************
% Informações que devem ser alteradas
% **************************************************
\titulo{\uppercase{Estudo sobre o uso do Docker na execução de aplicações web}}
\autor{\uppercase{Felipe Mendonça Ruhland}}
\orientador{Paulo Bueno}
\orientadortcc{Prof. \imprimirorientador, Dr. (SENAI/SC)}
\coordenador{Prof. Bobiquins Estevão de Mello, Me. (SENAI/SC)}
\coordenadortcc{Profa. Jaqueline Voltolini de Almeida, Me. (SENAI/SC)}
\examinador{Prof. Fulado de tal, Me. (SENAI/SC)}
\preambulo{Trabalho de Conclusão de Curso apresentado à Banca Examinadora do Curso Superior de Tecnologia em Análise e Desenvolvimento de Sistemas da Faculdade de Tecnologia do SENAI Florianópolis como requisito parcial para obtenção do Grau de Tecnólogo em Análise e Desenvolvimento de Sistemas.}
\proforientador{Professor Orientador: \imprimirorientador.}
\datadefesa{\uppercase{?? de julho de 2016}}
\local{Florianópolis/SC}
\data{2016}
% **************************************************

\instituicao{%
  SERVIÇO NACIONAL DE APRENDIZAGEM INDUSTRIAL 
  \par
  FACULDADE DE TECNOLOGIA SENAI/SC FLORIANÓPOLIS
  \par
  CURSO SUPERIOR DE TECNOLOGIA EM REDES DE COMPUTADORES}
\tipotrabalho{Trabalho de Conclusão de Curso}

% alterando o aspecto da cor azul
\definecolor{blue}{RGB}{41,5,195}

% informações do PDF
\makeatletter
\hypersetup{
     	%pagebackref=true,
		pdftitle={\@title}, 
		pdfauthor={\@author},
    	pdfsubject={\imprimirpreambulo},
	    pdfcreator={LaTeX with abnTeX2},
		pdfkeywords={abnt}{latex}{abntex}{abntex2}{trabalho acadêmico}, 
		colorlinks=true,      	% false: boxed links; true: colored links
		linkcolor=black,	% color of internal links
		citecolor=black,        % color of links to bibliography
		filecolor=magenta,      % color of file links
		urlcolor=black,
		bookmarksdepth=4
}
\makeatother
% --- 

% --- 
% Espaçamentos entre linhas e parágrafos 
% --- 

% O tamanho do parágrafo é dado por:
\setlength{\parindent}{1.3cm}

% Controle do espaçamento entre um parágrafo e outro:
\setlength{\parskip}{0.2cm}  % tente também \onelineskip

%\titlespacing\section{0pt}{12pt plus 4pt minus 2pt}{-6pt plus 2pt minus 2pt}

% ---
% compila o indice
% ---
\makeindex
% ---

% ----
% Início do documento
% ----
\begin{document}

% Retira espaço extra obsoleto entre as frases.
\frenchspacing 

% ----------------------------------------------------------
% ELEMENTOS PRÉ-TEXTUAIS
% ----------------------------------------------------------

\imprimircapa
\imprimirfolhaderosto*

\begin{folhadeaprovacao}

  \begin{center}
    {\ABNTEXchapterfont\bfseries\normalsize\imprimirautor}

    \vspace*{\fill}\vspace*{\fill}
    \begin{center}
      \ABNTEXchapterfont\bfseries\normalsize\imprimirtitulo
    \end{center}
    \vspace*{\fill}
        \imprimirpreambulo
    \vspace*{\fill}
        
   APROVADA PELA {\bfseries{COMISSÃO EXAMINADORA}}
   \par
   EM FLORIANÓPOLIS, \bfseries{\imprimirdatadefesa}
   \end{center}

   \assinatura{\imprimircoordenador \\ Coordenador do Curso} 
   \assinatura{\imprimircoordenadortcc \\ Coordenador de TCC} 
   \assinatura{\imprimirorientadortcc \\ Orientador} 
   \assinatura{\imprimirexaminador \\ Examinador}
   \begin{center}
    \vspace*{1cm}
  \end{center}
\end{folhadeaprovacao}

% Arquivos que devem ser alterados
\include{alterar/dedicatoria}
\include{alterar/agradecimentos}
\include{alterar/epigrafe}
\include{alterar/resumo}
\include{alterar/abstract}

% lista de figuras
\pdfbookmark[0]{\listfigurename}{lof}
\listoffigures*
\clearpage

% inserir lista de tabelas
\pdfbookmark[0]{\listtablename}{lot}
\listoftables*
\clearpage

% Arquivos que devem ser alterados
\include{alterar/siglas}
\include{alterar/simbolos}

% inserir o sumario
\pdfbookmark[0]{\contentsname}{toc}
\tableofcontents*
\clearpage

% ----------------------------------------------------------
% ELEMENTOS TEXTUAIS
% ----------------------------------------------------------
\textual

% PARTE - preparação da pesquisa
% ----------------------------------------------------------
%\part{Preparação da pesquisa}


% Informações que devem ser alteradas
% **************************************************
% ---
% Introdução
% ---
\chapter{INTRODUÇÃO}

Mais de dois terços das aplicações web rodam em ambiente unix, segundo \citeonline{w3techs}. Os sistemas são executados em servidores dedicados ou virtualizados. Os servidores dedicados são a maneira mais natural de servir uma aplicação web. São máquinas físicas, normalmente em datacerters, com um sistema operacional linux e com todo o hardware à sua disposição.
Entretanto, executar uma aplicação web em um servidor dedicado acaba por desperdiçar muitos recursos do mesmo. Para combater este desperdício, trabalha-se há décadas para aperfeiçoar um servidor que consiga evitar o disperdício, com a divisão dos recursos.

Nos últimos anos, usou-se muito as máquinas virtuais para aproveitar melhor os recursos dos servidores. Elas funcionam como novas máquinas dentro da máquina física e podem ser incluídas na rede como se fossem uma máquina física. Desta maneira, um servidor dedicado passa a ser multiplas máquinas, com seus próprios recursos e totalmente isoladas, que traz ainda mais segurança para os administradores de sistemas.

Com esta estratégia, os VPS (Servidores privados virtuais) tornaram muito mais acessíveis ao público em geral, pois era possível contratar um pequeno servidor virtualizado e ter total controle das configurações desde servidor. Isso colaborou com pequenos empreendedores que puderam expor seu trabalho de maneira mais economica e, com isso, abrir um leque de possibilidades para novas empresas.

A máquina virtual, por padrão, funciona como uma máquina totalmente nova. Ou seja, ela possui sistema operacional próprio, permissões individuais e recursos compartilhados com da máquina anfitriã. É possível instalar diversas versões do kernel, por exemplo, sem que uma interfira na outra. Contudo, observa-se que para cada máquina virtual criada num servidor dedicado existe uma sobrecarga do sistema operacional, pois além do sistema instalado na máquina anfitriã, cada máquina virtual possui seu sistema individual. Sabe-se, também, que o sistema operacional necessida de uma série de recursos para o bom funcionamento, de maneira que os recursos não podem ser muito ínfimo para não ocorrer problemas. Em paralalelo às máquinas virtuais, existe uma outra alternativa, mais leve, chamada de container.

Conteiners linux existem com a finalidade de isolar ambientes dentro de um sistema operacional linux. Eles não são máquinas virtuais, mas também conseguem restringir acesso, definir recursos próprios, mas não sobrepõe o sistema operacional. Ele usa o sistema da máquina anfitriã e, com isso, consegui utilizar menos recursos que a máquina virtual. Em razão dessas vantagens, muitos estudam para deixar a criação e manutenção desses containers uma tarefa mais fácil para os profissionais de ti. O caso mais conhecido nos últimos anos é da ferramenta Docker, que descomplicou a maneira de criar e gerir containers dentro de um sistema operacional. Pode-se dizer que o projeto é um sucesso, pois recebe mais utilizadores a cada dia e já possui investimentos na casa dos milhões de dólares.

Fala-se muito na arquitetura de microserviço, que traz vantagens para o desenvolvedor, por ter um escopo reduzido, facilita a criação e execução de testes, deploy e inúmeros outros fatores. Essa nova abordagem, segundo \citeonline{microservicos}, traz consigo a ideia de executar o microserviço em um container para simplificar a infraestrutura, de modo a facilitar a escalabilidade da aplicação e a sua manutenção. Com este pensamento, pode-se criar milhares de containers com a mesma aplicação, em ambientes isolados, independentes e seguros.

Este projeto tem por objetivo fazer um estudo sobre a tecnologia de containers linux para a execução de aplicações web, em especial o Docker.


\section{JUSTIFICATIVA}

Em razão do Docker, tem-se discutido muito o assunto de containers para execução de aplicações web, com muitos olhares positivos e muita adesão. Acredita-se que é um assunto muito relevante, pois já chamou a atenção dos gigantes da TI, como Google, Red Hat e Microsoft. Já existem inúmeros serviços que utilizam a ideia de container para execução de aplicações e muitas empresas já confiam neste conceito. Inclusive, a grande justificativa que se traz, a princípio, é a vantagem de ter uma aplicação que roda da mesma forma em desenvolvimento, testes, integração e produção. Não existe mais a desculpa que o ambiente não estava identico, pois agora, o ambiente é reduzido a um container linux.

Conforme descrito, os estudos focam a solução Docker, por ser o grande responsável pelo assunto atualmente e por ter chamado tanta atenção dos profissionais de TI, uma vez que o Docker é bem quisto por todas as etapas do desenvolvimento de software.

\section{OBJETIVOS}

Nesta seção são apresentados os objetivos do presente trabalho.

\subsection{Objetivo geral}

Estudo da solução de container linux para a execução de aplicações web.

\subsection{Objetivos específicos}

\begin{enumerate}
	\item{Introdução ao Docker}
	\item{Estudo do funcionamento do Docker}
	\item{Vantagens em executar aplicações em container}
	\item{Exemplos de utilização}
\end{enumerate}

\section{METODOLOGIA}

Dizer qual metodologia de trabalho será usada.

\section{ESTRUTURA DO TRABALHO}

Explicar como o trabalho está estruturado.

% ---
% Capitulo de revisão de literatura
% ---
\chapter{REVISÃO DA LITERATURA}\label{cap-revisao}

O processo de desenvolvimento de software é um trabalho complexo e depende de muitas etapas até a conclusão, conforme \citeonline{devmedia}.

\section{Introdução ao Docker}

\subsection{O que é Docker?}

Docker é uma ferramenta de linha de comando, que é executada em plano de fundo, e promove um servidor remoto para simplificar a experiência de instalar, executar, publicar e remover software, segundo \citeonline[p.6]{inaction}. Possibilita que um software seja posto em um container, junto com suas dependências, em uma unidade padrão de desenvolvimento de software, conforme \citeonline{sitedocker-whatdocker}. Desta forma, pode-se garantir que o software sempre vai ser comportar da mesma maneira, independente do ambiente que for executado.

Em 2008, Solomon Hykes fundou a empresa dotCloud para construir uma plataforma como serviço que fosse independente de linguagem. Outras plataformas como Heroku e Google App Engine tinham restrições de linguagem para rodar as aplicações, como Java, Python e Ruby. A dotCloud participou do programa de aceleração do Y Combinator em 2010, época que ficou em contato com novos parceiros e possibilidade de atrair grandes investimentos, conforme \citeonline[p.8]{using}. Entretanto, a maior virada ocorreu em março de 2013, quando o Docker foi lançado como um projeto de código aberto pela dotCloud. Em pouco tempo, a ferramenta caiu nos braços da comunidade de desenvolvedores. Grandes empresas de tecnologia como Red Hat, IBM, Google e Cisco, contribuem no desenvolvimento do produto, de acordo com \citeonline{techtarget}.

As primeiras versões do Docker eram um embrulho na biblioteca LXC, porém com grandes resultados de estabilidade e performance. Empresas como Spotify e Red Hat passaram a adotar a tecnologia para seus produtos, de acordo com \citeonline[p.9]{using}.

O ano de 2014 foi um ano muito especial para o Docker, pois foi o ano que recebeu grandes investimentos da Greylock Parteners e Sequoia Capital e passou a ter um valor de mercado em US\$ 400M (quatrocentos milhões de dolares). Em 2015, não foi muito diferente. Mais duas rodadas de investimentos ocorreram, que totalizou US\$ 180M (Cento e oitenta milhões de dolares), conforme  \citeonline{crunchbase-docker}. 

Entre as características marcantes da ferramenta pode-se considerar a leveza, pois compartilha recursos do sistema operacional; abertura, pois pode ser executado na grande maioria dos servidores linux e com versões instáveis para OSX e Windows; seguro, pois o container promove mais uma segunda camada protetora para o ambiente, segundo \citeonline{sitedocker-whatdocker}.

\subsection{O que Docker não é?}

\citeonline[p. 5]{up} trouxeram um subcapítulo muito interessante sobre o que não é Docker. Eles destacam que muitos vão tentar utilizar o Docker para sanar outras deficiências, como gerenciamento de configuração, por exemplo. Entretanto, Docker pode ajudar em muitos aspectos, mas ele nunca será um gerenciador de configurações. Enfim, o que Docker não é? Uma plataforma de virtualização, como VMware, KVM ou virtualbox; uma plataforma para núvem, como cloudstack ou openstack; Gestor de configuração, como puppet ou chef, apesar do Docker simplificar bastante o trabalho de configuração; um framework para deploy, como capstrano ou fabric; ferramenta para orquestração, como fleet ou mesos; um ambiente de desenvolvimento, como vagrant, apesar do Docker facilitar a composição do ambiente de desenvolvimento.

\citeonline[p. 6]{up} explicam que é bastante dificil compreender o Docker, mas que facilita o entendimento depois de estudá-lo melhor.

\subsection{O que são containers}

Nos sistemas unix era comum a expressão \textit{jail} para descrever um ambiente isolado que previnia o acesso a outros recursos do sistema, segundo \citeonline[p. 4]{inaction}. Somente em 2001, por meio do Solares da Sun, fez-se referência à palavra container para explicar este ambiente isolado, mesmo objetivo do \textit{jail}. Ainda em 2001, a Parralles Inc lançou uma solução comercial chamada Virtuozzo, que em 2005 foi aberto o código do projeto com o nome OpenVZ. Em 2008 o projeto Linux Container (LXC) trouxe consigo CGroups, namespaces e a tecnologia chroot para promover uma solução completa com container. Finalmente, em 2013, Docker foi lançado e com ele a grande adoção por parte dos desenvolvedores da tecnologia de containers, como conta \citeonline[p.3]{using}. Em resumo, containers são aplicações encapsuladas com suas depedências.

Num estudo preliminar, nota-se que o container é mais leve que uma máquina virtual, pois compartilha o sistema operacinal para rodar as aplicações. Pra completar, ainda elenca outras diferenças entre as máquinas virtuais como o compratilhamento de recursos com a máquina anfitriã, podem ser ligadas e desligadas numa fração de segundos; a portabilidade de ambientes evita os bugs originados em decorrência dessa diferença de ambiente; a leveza dos containers possibilitam que sejam executados centenas de containers simultaneos, bem como uma configuração muito próxima da executada em produção; e trazem uma gama de vantagens aos desenvolvedores de software que trabalham com equipes diferentes, de modo que para executar projetos dependentes, basta executar o container pretendido, sem que haja necessidade de configuração exaustiva.

\subsection{Containers vs máquinas virtuais}

A documentação oficial exalta que um deploy em uma máquina virtual inclui uma aplicação, as dependências necessárias (binários e bibliotecas) e um sistema operacional, que pode ter um tamanho considerável de alguns Gigabytes. Ainda conforme \citeonline{sitedocker-whatdocker}, containers inclui a aplicalção e suas dependências (binários e bibliotecas), porém compartilha o kernel com outros containers e mantem-se num \textit{userspace} isolado do sistema operacional. Além de ser independente de infraestrutura.

Por definição, a máquina virtual tem um caráter de longevidade. Ela tem por objetivo abstrair os servidores físicos para dar mais flexibilidade na publicação de aplicações. \citeonline[p.15]{up} ensinam que mesmo as máquinas virtuais em serviços de núvem, tem por natureza um caráter de longa duração, pois o custo de ligar e desligar uma máquina é muito grande. Em contra partida, um container pode ser usado para uma atividade de segundos de duração e seu custo de vida é muito mais econômico, em comparação com a máquina virtual.

De acordo com \citeonline[p.5]{inaction}, máquinas virtuais promovem um hardware virtual e pode levar minutos para inicializar e estabelecer os recursos necessários para rodar um cópia de um sistema operacional.

O mesmo \citeonline[p.5]{inaction} ensina que diferentemente das máquinas virtuais, os containers não usam hardware virtuais, pois as aplicações que rodam em container utilizam a interface do kernel linux da máquina anfitriã. Por isso, não existe nenhuma camada entre a aplicação e a máquina anfitriã e nenhum recurso é desperdiçado. Deve-se lembrar que Docker não é uma tecnologia de virtualização e sim uma ferramenta para criar, gerenciar e remover containers.

\section{Funcionamento do Docker}

\subsection{Arquitetura Docker}

Ressalta-se a importância de conhecer a estrutura do Docker para obter um entendimento pleno do funcionamento da ferramenta e as vantages que ela pode trazer. O Docker engine é responsável pelo serviço docker, que atua em background e gerencia a criação, manuteção e remoção dos containers; a construção e armazenamento das imagens, e pelo cliente de linha de comando que se comunica com o serviço por http. O cliente docker é, normalmente, o primeiro passo para aprender a utilizar a ferramenta, como explica \citeonline[p.36]{using}.

Existe também o Docker Registry, que é responsável por gerenciar e armazenar as imagens oficias e das organizações. O registry oficial é o Docker Hub e, por padrão, todo serviço docker utiliza este registry para buscar as imagens para criar os containers. Empresas costumam ter seu próprio registry para gerenciar suas imagens e permitir a distribuição das mesmas.

Para a criação dos containers, Docker utiliza a biblioteca runc, que também foi desenvolvida pelo Docker. Para gerenciar os recursos do container, utiliza-se de \textit{cgroups} para controlar o uso do processamento, da memória e restrigir o acesso aos periféricos, segundo \citeonline[p.123]{inaction}. Por outro lado, com a finalidade de garantir o isolamento, utiliza-se \textit{namespaces} para garantir que o sistema de arquivos, rede e processos são completamente separados da máquina anfitriã, como leciona \citeonline[p.37]{using}.

\subsection{Control groups}

Segundo \citeonline{KernelOrg}, control groups promovem um mecanismo para agregar e particionar conjuntos de tarefas e seus fituros filhos em um grupo hierárquico com comportamento especializado. Em outras palavras, controls groups permitem a definição de limites em recursos para processos e seus dependentes, que é utilizado pelo Docker para controlar o uso de recursos como processamento, memória, leitura em disco e entrada e saída de rede. É com o control group que o Docker consegue expor as estatísticas de seus containers. Os control groups são uma feature do kernel linux e não existe a necessidade de utilizar o Docker para implementá-lo, entretanto a ferramenta abstrai o comportamento dos control groups para facilitar seu uso.

\citeonline{CloudSigma} explica que se houverem muitos containers na mesma máquina, deve-se fazer uso dos control groups para gerenciar o uso de recurso entre os containers para que sejam priorizados os serviços mais importantes.

\subsection{Namespaces}

Dentro de cada container, verifica-se um sistema de arquivos, interfaces de rede, discos e outros recursos que parecem ser únicos do container, com exceção do kernel compartilhado. Para um container, a interface de rede parece ser realmente singular e exclusiva, como se fosse de um servidor normal. Este comportamentp só é permitido graças aos namespaces, que usa um recurso global e faz parecer que ele é esclusivo de um container, como explicam \citeonline[p.161]{up}.

Os containers criados pelo Docker, são isolados em diferentes aspectos, como: PID (Process identifiers and capabilities), UTS (Host and domain name), MNT (File system access and structure), IPC (Process communication over shared memory), NET (Network access and structure) e USR (User names and identifiers). 

Segundo \citeonline[p.6]{inaction}, sem um PID namespace, o processo executado dentro de um container compartilharia o id de espaço com outros processos em execução na máquina anfitriã. Isso arriscaria o isolamento e permitiria que processos executados dentro de um container tomassem controle de outros processos na máquina anfitriã. Para novos containers, é criado um namespace com um ponto de montagem com intuito de isolar o sistema de arquivos. O namespace IPC previne que processos acessem dados na memória de outro container. Ainda que não tenha sido implementado pelo Docker, o namespace USR tem por objetivo permitir que um usuário na máquina anfitriã possua as mesmas permissões num containers, se assim for feito, conforme \citeonline[p.112]{inaction}. 

\subsection{Volumes}

Por padrão, os containers são criado com carater imutável, segundo \citeonline[p.?]{inaction}. \citeonline[p. 66]{up} ensinam que os containers possuem armazenamento de natureza efêmera e o espaço em disco alocado dificilmente é adequado para os projetos. Para solucionar estes problemas, existem os volumes. Estes são definidos na criação da imagem e montados no momento da criação do container. Ou seja, para containers que necessitem de armazenamento de dados, é possível criar um volume para armazenar estes dados. Um volume funciona como um container com o único intuito de persistir os dados e disponibilizar ao container se for necessário.

Conforme \citeonline[p. 53]{using}, os volumes ainda podem ser utilizados para compartilhar dados entre o host e os containers, bem como entre dois containers. Isso permite o polimorfismo entre os containers, pois imagens criada de forma genérica podem ser utilizadas em conjunto com volumes para modificar o comportamento do containers conforme os dados do volume, segundo \citeonline[p. 74]{inaction}. Uma imagem criada para servir conteúdo estático pode se aproveitar desse padrão de projeto para generalizar o seu uso, uma vez que seu comportamento será alterado conforme for definido o seu volume, por exemplo. Existem dois tipos de volumes no ecosistema Docker: Volume vinculado á maquina anfitriã e o volume gerenciado pelo Docker.

\subsubsection{Volume vinculado ao host}

Conforme \citeonline{sitedocker-dockervolumes}, os volumes vinculados ao host são pontos de montagem do disco da máquina anfitriã no disco do container. Funciona como um diretório compartilhado e é uma ótima forma para compartilhar os arquivos entre a máquina anfitriã e o container. Define-se o diretório (ou arquivo) que será montado no container e o caminho do diretório (ou arquivo) no container. Se houver arquivos no caminho informado no container, este serão desconsiderados e os arquivos definidos na máquina anfitriã serão utilizados. Qualquer alteração nestes arquivos, serão aplicados diretamente na máquina anfitriã.

Quando é utilizada esta estratégia, é possível, inclusive, utilizar o mesmo ponto de montagem para um segundo container que terá os dados e poderá alterá-lo da mesma forma. Assim, é possível que dois containers utilizem o mesmo ponto de montagem de arquivos e possam usufruir dos mesmos com as eventuais alterações. Existe a possibilidade de evitar que containers alterem arquivos e prejudiquem o funcionamento de outros, precisa-se definir uma propriedade de \textit{somente leitura} para manter o isolamento e assegurar que não ocorra modificações indesejadas.

\subsubsection{Volume gerenciador pelo Docker}

Ainda, segundo \citeonline{sitedocker-dockervolumes}, pode-se criar um container com objetivo único de armazenar os dados de outro container. Pra isso, precisa-se de um container para os dados e um outro para a aplicação. Esta estratégia tem caráter presistente, pois mesmo que o container de aplicação seja corrompido ou removido, o volume será mantido e poderá ser utilizado por um novo container. Para remover o volume, contudo, é necessário que seja explicito na remoção. Caso contrário, o volume permanecerá na máquina com o espaço alocado. \citeonline[p. 76]{inaction} chama este volume de volume órfão, que deve ser removido de maneira manual e cuidadosa para não remover um outro volume por engano.

\subsection{Camada de Rede}

A comunicação entre containers é algo essencial para o bom funcionamento das aplicações, como conexão ao banco de dados, ao cache ou a qualquer outro serviço disponível na rede. Conforme \citeonline{sitedocker-dockernetworks}, deve-se ter o controle da camada de rede a qual a aplicação é executada, de maneira segura, para promover o completo isolamento para o container. Segundo \citeonline[p.13]{up}, o Docker acaba agindo como uma ponte virtual entre o dispositivo o qual trafega os dados de um lado para o outro, como uma pequena rede virtual.

Por padrão, o Docker apresenta 4 (quatro) possibilidades de rede para seus containers: container fechado, em ponte, unido e aberto.

\subsubsection{Container fechado}

A maneira mais segura de rede com container, pois não permite nenhum tráfego de rede. O processo que rodar neste container terá acesso apenas a interface de loopback. Apesar de possui grande segurança, não permite que softwares sejam atualizados e nenhuma comunicação seja efetuada. \citeonline[p.103]{inaction} ensina que dificilmente será utilizada esta estratégia de rede, que deixa o container sem acesso à rede externa, entretanto pode ser útil para volumes gerenciados pelo Docker, aqueles em containers, para atividades de backup, processamento offline ou ferramentas de diagnóstico. Deve-se conhecer as formas de utilização de rede para decidir qual forma será utilizada.

Em contra partida, os containers em ponte são a forma mais utilizada pelos desenvolvedores.

\subsubsection{Container em ponte}

Utilizada por padrão, a estratégia de rede de containers em ponte possui um nível normal de isolamento, uma vez que possue uma interface privada e utiliza a rede de maneira natural. De acordo com \citeonline[p.89]{inaction}, os containers em ponte não são acessíveis pela máquina anfitriã, em razão do sistema de firewall. A estratégia padrão não permite acesso pela interface de rede externa, o que significa que não existe a possibilidade de descobrir este container fora da máquina anfitriã. A maneira mais natural de acessar serviço de um container pela máquina anfitriã, é expor as portas necessárias e vincular à maquina anfitriã, conforme \citeonline{sitedocker-dockernetworks}.

Uma vez que uma porta é exposta e vinculada à maquina anfitriã, os demais containers terão acesso ao serviço exposto e poderão firmar uma relação entre os serviços.

\subsubsection{Container unido}

De maneira resumida, os containers unidos representam dois containers com estratégias distintas: um fechado e outro em ponte. O objetivo principal é ter, por opção, as duas maneiras de comunicação em containers isolados. Desta forma, pode-se monitorar uma aplicação, promover backups ou rotinas em batch de maneira mais simples. A documentação oficial do \citeonline{sitedocker-dockernetworks}, inclusive, não apresenta esta estratégia e a única fonte foi \citeonline[p.96]{inaction}.

Por último, tem-se a estratégia mais permissiva e insegura de todas: o container aberto.

\subsubsection{Container aberto}

No que diz \citeonline[p.96]{inaction}, os containers abertos são perigosos e tem total acesso a rede da máquina anfitriã, que incluem acesso aos serviços criticos da máquina. Neste caso, não se possui nenhuma forma de isolamento de rede e somente deve ser utilizado em casos de extrema necessidade. 

% ---
% Procedimentos metodológicos
% ---
\chapter{PROCEDIMENTOS METODOLÓGICOS}

Este capítulo aborda os métodos e as técnicas utilizadas neste trabalho, de modo que permitiram o tratamento do tema proposto.

O estudo de caso foi feito de maneira descritiva, no qual a literatura foi analisada e interpretada para a elaboração de um parecer final sobre o assunto. O procedimento utilizado foi a pesquisa bibliográfica, para o melhor entendimento do funcionamento da ferramenta e seus efeitos no ambiente de desenvolvimento de software.

Ainda, buscou-se a utilização do método qualitativo para a elaboração do trabalho. Por se tratar de um tema extremamente novo, utilizou-se os livros mais atuais, para manter a coerência entre o estado atual da ferramenta, artigos de documentação da própria ferramenta, que é de excelente qualidade, e artigos na internet que dissertam sobre o tema com um foco mais prático.

% ---
% Resultados
% ---
\chapter{RESULTADOS E DISCUSSÕES}

Neste capítulo, dissertar-se-á sobre as dificuldades encontradas no processo de desenvolvimento de software, desde o desenvolvimento, distribuição e, por fim, a publicação.

\section{Problemas comuns na rotina de desenvolvimento de software}

\subsection{Ambiente de Desenvolvimento}

Segundo \citeonline{softwarequality}, no desenvolvimento de softwares o ambiente de desenvolvimento é o conjunto de processos e ferramentas usados para auxiliar a criação do programa ou software. Empresas de tecnologia possuem um checklist ou wiki para orientar o programador na configuração do ambiente de desenvolvimento. Este processo envolve guias de estilo de codificação, instalação de IDEs e plugins, configurações de banco de dados, entre outros detalhes. Em seguida, deve-se configurar as aplicações para que sejam executadas em modo de desenvolvimento no ambiente do desenvolvedor, que também inclui dependências com versões específicas e configurações ímpares, bem como ajustes de depuração e execução de testes.

Um grande desafio que os desenvolvedores enfrentam é orquestrar configuração do ambiente de desenvolvimento, pois este ambiente acaba por ser simplificado em comparação ao ambiente de produção. É muito comum o software correr de maneira estável em desenvolvimento, mas não obter o mesmo resultado em produção. Seja banco de dados em memória, configurações padrão ou uma arquitetura mais modesta, os ambiente de desenvolvimento são mais simples para garantir que o desenvolvedor não perca tempo com configurações e ajustes e passa a focar no objetivo principal que é a implementação de funcionalidades. 

\subsection{Processo de integração}

Quando uma equipe de desenvolvimento trabalha em uma nova entrega para o cliente, esta deve paralelizar os esforços para buscar um entrega mais célere e satisfazer o cliente. Este trabalho em separado deve ser integrado para a realização de testes e garantir que as novas alterações não quebraram comportamentos antigos. Para isso, submete-se os novos códigos a um processo de integração, o qual tem por objetivo garantir o sucesso das funcionalidades, que nenhuma dependência mudou o seu comportamento e que o programa funciona em sua plenitude, segundo \citeonline{continuousintegration}.

Em muitos casos, esta integração deve ocorrer em um ambiente controlado para poder reproduzir os dados dos testes e, ainda, muitos deles necessitam de outros serviços para garantir o sucesso, como chamadas de rede, consultas à bancos de dados, entre outros. Desta forma, percebe-se que existe mais um ambiente a ser controlado pela equipe de evolução de funcionalidades.

\subsection{Ambiente de Homologação}

Grandes empresas dispõe de um ambiente de homologação que precede o ambiente de produção. Isto ocorre, de maneira geral, para previnir erros e desacertos entre ambientes. Este procedimento sempre foi muito bem aceito como destaca \citeonline{profissionaisti}, mas será que o ambiente de homologação é realmente necessário?

O ambiente de homologação deve representar o ambiente de produção e exige, também, que seja feita uma instalação completa do software, de suas dependências, alterações de banco de dados e configurações de ambiente. Mesmo que seja utilizada uma ferramenta de automatização para a instalação, um ambiente de homologação exige atenção e manutenção para operar normalmente, conforme \citeonline{softwarequality-staging}.

\subsection{Distribuição do software}

Sabe-se que algumas linguagens necessitam de algum tipo de preparação antes de ser instalada no servidor de produção e a grande maioria necessita de algum tipo de compilação. Seja de seus fontes ou de suas dependências. Após a finalização dos arquivos fontes, dependências e configuração, é hora de distribuir a nova versão do software nos servidores de produção. Muitos optam por criar um arquivo compactado com todos os arquivos necessários e transferir este arquivo pela rede, que acabam por ser muito pesados e obrigam que arquivos que já foram transmitidos tenham que ser novamente enviados.

Mesmo que este trabalho tenha sido automatizado de alguma forma, por scripts ou outros softwares, ainda se faz necessário que estes arquivos sejam enviados um a um para os novos servidores. Ainda, corre-se o risco de ter algum arquivo corrompido ou que tenha sido gerado de maneira errada, o que pode ocasionar falha na atualização do software.

\subsection{Instalação do Software}

Após a implementação de uma ou mais funcionalidade, uma nova versão é gerada e deve ser lançada no ambiente de homologação ou produção. Normalmente este processo é arduo e depende de uma equipe especializada para concluir esta etapa. A equipe de desenvolvimento deve passar detalhes da implementação e as peculiaridades da versão. Qualquer erro ocorrido deve ser reiniciado o processo de instalação e pode provocar consequências irreversíveis, como corrupção de dados. Após a instalação, pode ocorrer a necessidade de ampliar os servidores para servir um tráfego maior de usuários e isso acarreta na instalação em novas máquinas. Mas, é claro, que essa instalação não acontece há tempo de suprir a necessidade de tráfego.

\subsection{Escalabilidade}

O aumento repentino de tráfego em aplicações web demandam muita estratégia da equipe de infraestrutura para que os usuários não sintam lentidão ou não recebam resposta do servior. Essa estratégia deve conter um rápido ataque para suprir esta necessidade e não pode contar com a instalação de novas máquinas físicas, pois não haveria tempo hábil para tal. Nos dias de hoje, uma empresa que oferece serviços como produto não pode deixar de prestar o serviço sob pena de ter o descrédito pelos usuários e resultar no término dos negócios. Portanto, esses casos exigem que a equipe de infraestrutura possua condições de ampliar o servidor web.

\subsection{Entregabilidade}

A dificuldade de instalar um software normalmente é medida pela frequência que ela ocorre. Quando ocorre frequentemente, deixa a instalação simples e rápida. Se ocorre com pouca frequência, deixa a instalação complexa e demorada. A forma tradicional de instalação normalmente é mais dolorosa e pouco frequente, em razão de diversos fatores como dependências, scripts de migração de banco de dados e etc. Assim, a entregabilidade é prejudicada, pois uma nova funcionalidade leva tempo para ser instalada em produção.

\subsection{Segurança}

Nos servidores físicos são comuns a execução de várias aplicações web na mesma máquina para utilizar o máximo de recurso possível. Entretanto, isso pode ser muito perigoso, pois uma vulnerabilidade em uma aplicação pode dar acesso à maquina que rodam as outras. Da mesma forma, um vazamento de memória pode impedir o bom funcionamento das demais aplicações e acabar derrubando as demais.


% ---
% Conclusão
% ---
\chapter{CONCLUSÃO}

\section{Vantagens em executar aplicações em containers}

Ante os problemas expostos, verifica-se que muitos deles são grandes candidatos a não existirem, uma vez que seja adotado o uso de docker em todas as etapas do desenvolvimento de software. Deve-se manter uma hierarquia de imagens para facilitar, ainda mais, a estrutura de dependências dos projetos.

\subsection{Imagens Docker}

Ao utilizar Docker é comum, e indicado, que seja feita uma hierarquia de imagens para otimizar o tamanho das imagens e, por concequência, diminuir o tempo de instalação. É sugerido pelo \citeonline{sitedocker-dockerfile} algumas práticas para criar as imagens da melhor maneira. A primeira sugestão é pensar que os containers devem possuir natureza efêmera, que deva ser destruído e criado sem prejuízo algum. Na grande maioria dos casos, diz-se boa prática de criar um arquivo com a lista de diretórios e arquivos que devem ser ignorados na criação das imagens. Arquivos de build, logs e de sistema de controle de versão são bons exemplos de arquivos que devem ficar fora do container.

Outra boa indicação é evitar a instalação de pacotes básicos, como editores de texto, por exemplo, que não será utilizado em produção e acabam ocupando espaço na imagem e aumentando o tempo de construção da mesma. Outra dica valiosa é manter um processo por container e abusar da arquitetura de micro-serviços. Se for preciso se comunicar com outros serviços, deve-se utilizar as estratágias de rede para manter os serviços comunicáveis e trafegar os dados sempre que preciso.

Recomenda-se, também, a utilização do menor número de layers possível, pois, além de tornar o arquivo de imagem mais legível, ele possui menos etapas e pode manter um cache maior. Procura-se, ainda, manter comando de múltiplas linhas em ordem alfabética para facilitar a compreensão.

Criar imagens reusáveis é uma ótima estratégia e pode poupar tempo e manutenção, uma vez que é possível alterar o comportamento das imagens conforme os volumes montados ao container, segundo \citeonline{tutum}.

\subsection{Dependências de desenvolvimento}

Em princípio, notou-se que as aplicações web atuais estão muito complexas e com muitas dependências. Isso torna o desenvolvimento de software um pouco lento, pois são inúmeras configurações que o profissional deve se atentar para poder executar o seu trabalho de maneira desempedida, segundo \citeonline[p.14]{inaction}. Para isso, tem-se o Docker Compose, uma ferramenta que auxilia a criação de serviços interconectados, configurável por arquivos \textit{yaml} e que são controláveis por um programa de linha de comando, conforme \citeonline[p.232]{inaction}.

Além de evitar que o desenvolvedor seja obrigado a instalar serviços como banco de dados, gerenciador de fila, cache, entre outros, o Docker Compose se encarrega de orquestrar estes seviços de forma automatizada e interligadas, utilizando links para simplificar a conexão entre elas, de acordo com \citeonline[p111]{up}. Sem sombra de dúvias, é a melhor maneira de criar um ambiente de desenvolvimento do zero. Isso torna a iniciação de novos desenvolvedores mais rápida e com menos tempo para adaptação, desde que saiba o básico de Docker.

O Docker é a ferramenta perfeita para falicitar o ambiente de desenvolvimento, pois os containers tendem a substituir as dependências como banco de dados, cache, sistema de filas e etc, de maneira simples e leve. Esta solução pode ser implementada na própria máquina do desenvolvedor, uma vez que leva segundos para executar um container e ele tem um impacto menor no sistema, em razão do compartilhamento dos recursos do sistema. Com uma única linha de comando é possível executar um banco de dados pronto para ser utilizado.

Se o projeto deve ser testado em mais de um banco, verifica-se ainda mais benefícios, pois é possível parar e executar containers de maneira muito fácil. Isso deixa a troca de banco mais leve para ser executado no ambiente de desenvolvimento e dá mais flexibilidade para os testes, sem depender de um ambiente de testes.

Outro grande benefício é abstrair a configuração de banco de dados de desenvolvedores júnior, por exemplo. Estes podem simplesmente buscar uma imagem pronta para uso e não ter que perder tempo com configurações para conseguir executar o projeto.

Uma outra depemdência que cabe citar, é o backend para o desenvolvimento de interfaces. Normalmente desenvolvedores frontend são dependentes de outros desenvolvedores para preparar um ambiente atualizado, em funcionamento e com dados úteis para os testes. Com o Docker, o próprio desenvolvedor frontend pode escolher a imagem que gostaria de utilizar e pode usar configurações pré definidas, o que reduz o tempo de preparação e aumenta o tempo de desenvolvimento.

Entende-se que toda vez que um desenvolvedor ganha tempo de desenvolvimento ou gasta menos tempo arrumando ambientes, a empresa tem menos prejuízo. Esse é um grande argumento para adotar a ferramenta e começar a reduzir os gastos desnecessários com preparação e ambientes de desenvolvimento.

Conforme ensina \citeonline{brikman}, o Docker deixou a instalação de softwares de terceiros uma tarefa muito mais fácil, pois basta configurar as variáveis e rodar o container para executar a aplicação. Lembra-se que a grande maioria dos software são passíveis de serem executados em containers. Também comenta que é muito mais limpo testar novos serviços, uma vez que a instalação ocorre num container e não necessita de instalação de dependências na máquina de trabalho. Desta forma, o seu sistema continua enxuto e problemas com muitas dependências.

Ainda, garante uma camada extra de segurança pois, caso sejam executados aplicações maldosas, o container vai manter o isolamento com a máquina anfitriã e vai proteger o sistema de arquivos e os dispositivos conectados.

\subsection{Composição de containers}

É normal um desenvolvedor começar a utilizar o Docker e se deparar com uma grande quantidade de containers ou de configurações. Pra resolver este problema, existe o Docker Compose. Ele é uma ferramenta voltada para composição de multiplos containers conectados e promover um ambiente de desenvolvimento mais simples. Ele possui um arquivo de configuração no formato yaml e é possível criar diversas configurações.

\section{Distribuição}

Para a distribuição do software, sabe-se que é, também, uma tarefa muito árdua, que na grande maioria dos casos necessita de uma equipe especializada no assunto. Com Docker Registry este trabalho foi facilitado, de modo que a distribuição das imagens são feitas de maneira automática e podem ser construídas de maneira muito rápida, com o uso de imagens base, como explica \citeonline[p.44]{using}. Lembra-se, contuto, que as boas práticas ensinam que as imagens só devem ser publicadas no registry após os testes unitários e de aceitação.

\section{Publicação}

Por fim, o deploy deve ser automático e não deve apresentar problemas se for utilizado o Docker Swarm, que é uma ferramenta de orquestração para construção de cluster de serviços docker, como ensina \citeonline[p.255]{inaction}. Ele consegue atualizar o cluster de serviços Docker de forma rápida e segura, pois nossos serviços web devem operar com conexão criptogradada, segundo \citeonline[p.129]{up}.

Desta forma, concluí-se que a ferramenta Docker traz benefícios em todas as etapas de desenvolvimento de software, com a sua distribuição de imagens, publicação em produção e manutenção do cluster de serviços.

\section{Estudo de caso}

Atualmente, a Gerência de Tecnologia da Softplan desenvolve software com o auxílio da ferramenta Docker para simplificar o desenvolvimento, distribuição e publicação. O projeto é composto por uma api, um projeto web, um programa para consumir um feed, um banco de dados relacional, um sistema de cache e um broker. Na stack ainda existem um agregador de log, um monitor de exceções, servidor de integração contínua e documentação dos projetos. 

São 10 (dez) aplicações diferentes, com configurações singulares e conexões específicas. Criar esta configuração manualmente seria possível, mas tomaria um tempo precioso. Este projeto já começou com o intuito de apresentar um retorno desde o seu início. Ou seja, já deve apresentar aos usuários um valor e justificar o investimento.

Desta forma, optou-se por utilizar Docker e acelerar o processo de distribuição do projeto.

\subsection{Desenvolvimento}

Para o desenvolvimento, utiliza-se Docker Compose para gerenciar os containers e falicitar o uso por novos desenvolvedores e diminuir a curva de aprendizado para começar a desenvolver em qualquer das aplicações. A primeira imagem Docker foi da api. Utilizou-se a imagem base do alpine linux, para manter o tamanho da imagem pequeno, com python 3 instalado e as dependências gerenciadas pelo python-pip. A execução do container é feita pelo supervisor e pelo uWSGI.

Para a aplicação web, decidiu-se utilizar bower e grunt para montar as dependências e criar os arquivos compactados e minificados. Ainda, para servir os arquivos staticos, escolheu-se o Nginx para servidor web. Para o consumidor de feed, utilizou-se a mesma imagem base da api, porém sem a necessidade dos serviços web, pois não há a necessidade de executar um servidor.

% **************************************************

% ----------------------------------------------------------
% ELEMENTOS PÓS-TEXTUAIS
% ----------------------------------------------------------
% \postextual

% ----------------------------------------------------------
% Referências bibliográficas
% Arquivos que devem ser alterados
\bibliography{alterar/referencias}

% ----------------------------------------------------------
% Glossário
% ----------------------------------------------------------
%
% Consulte o manual da classe abntex2 para orientações sobre o glossário.
%
%\glossary

% ----------------------------------------------------------
% Apêndices
% ----------------------------------------------------------

% Informações que devem ser alteradas
% **************************************************
% ---
% Inicia os apêndices
% ---
\begin{apendicesenv}

\chapter{Código fonte}
Código de minha autoria. O apêndice é opcional ao TCC e deve ser elaborado pelo próprio autor. Destina-se a complementar as ideias, sem prejuízo do tema do trabalho. Segue um exemplo:

\scriptsize
\begin{lstlisting}
#include <stdio.h>

int main() {
  printf("Ola mundo !\n");
  return 0;
}
\end{lstlisting}

\end{apendicesenv}

% ----------------------------------------------------------
% Anexos
% ----------------------------------------------------------
\begin{anexosenv}

\chapter{Pesquisa IBGE}
O anexo é opcional ao TCC e são informações não elaboradas pelo próprio autor, mas que tem como objetivo complementar as ideias, sem prejuízo do tema do relatório.

\end{anexosenv}

% Etiqueta para auxiliar contagem do numero de paginas do texto e dos elementos pos-textuais
\label{nropaginas}

% **************************************************

%---------------------------------------------------------------------
% INDICE REMISSIVO
%---------------------------------------------------------------------
\printindex

\end{document}
